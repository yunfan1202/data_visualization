- date: 2/4
  title: >
    Week 1 <b>可视化概述</b> <a href="lec1 - introduction.pdf">[slides]</a>
  slides:
  topics:
    - Course syllabus and requirements <br/>
    - Introduction to AI and AI research
  readings:
    - <a href="https://arxiv.org/abs/2209.03430">Foundations and Trends in Multimodal Machine Learning&#58; Principles, Challenges, and Open Questions</a> <br/>
    - <a href="https://arxiv.org/abs/1705.09406">Multimodal Machine Learning&#58; A Survey and Taxonomy</a> <br/>
    - <a href="https://arxiv.org/abs/1206.5538">Representation Learning&#58; A Review and New Perspectives</a> <br/>

- date: 2/6
  title: >
    Week 1 <b>视觉感知与视觉通道</b> <a href="lec1.2 - AI research.pdf">[slides]</a>
  slides:
  topics:
    - Introduction to AI and AI research <br/>
    - Generating ideas, reading and writing papers, AI experimentation
  readings:

- date: 2/11
  title: >
    Week 2 <b>可视化流程框架与图表设计</b> <a href="lec2 - data.pdf">[slides]</a>
  slides:
  topics:
    - Common data modalities <br/>
    - Data collection strategies <br/>
    - Training objectives and generalization
  readings:
    - <a href="https://www.science.org/doi/abs/10.1126/science.aaa8415">Machine learning&#58; Trends, Perspectives, and Prospects</a> <br/>
    - <a href="https://arxiv.org/abs/1206.5538">Representation Learning&#58; A Review and New Perspectives</a> <br/>
    - <a href="https://arxiv.org/abs/2209.03430">Foundations and Trends in Multimodal Machine Learning&#58; Principles, Challenges, and Open Questions</a> <br/>
    - <a href="https://arxiv.org/abs/2104.13478">Geometric Deep Learning&#58; Grids, Groups, Graphs, Geodesics, and Gauges</a> <br/>

- date: 2/14
  title: >
    Week 2 <b>Python数据获取与处理</b> <a href="Debugging Tips.pdf">[slides]</a>
  slides:
  topics:
    - Getting started with PyTorch <br/>
    - Huggingface packages <br/>
    - Debugging machine learning models
  readings:
  - <a href="https://karpathy.github.io/2019/04/25/recipe/">A Recipe for Training Neural Networks</a> <br/>
  - <a href="https://colab.research.google.com/drive/1EDsjYRrAiujUew0GRJ_hyVoNMsSDnlnx?usp=sharing">Fine-tuning a Code LLM on Custom Code on a single GPU</a> <br/>
  - <a href="https://colab.research.google.com/drive/1SoTu6gvYcLNDqPwNPTWmsSYF-l-UfHPx?usp=sharing">MAS.S60 Pytorch Introduction</a> <br/>

- date: 2/18
  title: >
    Week 3 <b>No class, shifted President's day</b>
  slides:
  topics:
  readings:

- date: 2/20
  title: >
    Week 3 <b>Project proposal presentations</b>
  slides:
  topics:
  readings:

- date: 2/25
  title: >
    Week 4 <b>pyecharts入门</b> <a href="lec3 - models.pdf">[slides]</a>
  slides:
  topics:
    - Structure and invariances <br/>
    - Temporal sequence models <br/>
    - Spatial convolution models <br/>
    - Models for sets and graphs
  readings:
    - <a href="https://arxiv.org/abs/2104.13478">Geometric Deep Learning&#58; Grids, Groups, Graphs, Geodesics, and Gauges</a> <br/>
    - <a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words&#58; Transformers for Image Recognition at Scale</a> <br/>
    - <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> <br/>
    - <a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> <br/>
    - <a href="https://arxiv.org/abs/1703.06114">Deep Sets</a> <br/>
    - <a href="https://arxiv.org/abs/1710.10903">Graph Attention Networks</a> <br/>

- date: 2/25
  title: >
    Week 4 <b>pyecharts进阶</b>
  slides:
  topics:
  readings:
    - <a href="https://arxiv.org/pdf/2410.09649">Learning the Bitter Lesson</a> <br/>
    - <a href="https://arxiv.org/pdf/2303.06173">Unifying Grokking and Double Descent</a> <br/>
    - <a href="https://arxiv.org/pdf/2209.01610">Generalization in Neural Networks</a> <br/>
    - <a href="https://arxiv.org/pdf/2306.11644">Textbooks are all you Need</a> <br/>
    - <a href="https://arxiv.org/pdf/2207.07528">A Conceptual Pipeline for Machine Learning</a> <br/>

- date: 3/4
  title: >
    Week 5 <b>时空数据可视化</b> <a href="lec4 - multimodal.pdf">[slides]</a>
  slides:
  topics:
    - Heterogeneity, connections, and interactions <br/>
    - Multimodal technical challenges <br/>
    - Alignment and transformers
  readings:
    - <a href="https://arxiv.org/abs/2209.03430">Foundations and Trends in Multimodal Machine Learning&#58; Principles, Challenges, and Open Questions</a> <br/>
    - <a href="https://arxiv.org/abs/2005.10243">What Makes for Good Views for Contrastive Learning?</a> <br/>
    - <a href="https://link.springer.com/article/10.1007/s13735-019-00187-6">Characterization and classification of semantic image-text relations</a> <br/>
    - <a href="https://arxiv.org/abs/2210.01936">When and why vision-language models behave like bags-of-words, and what to do about it?</a> <br/>

- date: 3/6
  title: >
    Week 5 <b>文本数据可视化</b>
  slides:
  topics:
  readings:
  - <a href="https://arxiv.org/abs/2301.03728">Scaling Laws for Generative Mixed-Modal Models</a> <br/>
  - <a href="https://arxiv.org/abs/2404.07965">Not All Tokens Are What You Need for Pretraining</a> <br/>
  - '<a href="https://arxiv.org/abs/2209.06794">PaLI: A Jointly-Scaled Multilingual Language-Image Model</a> <br/>'
  - <a href="https://arxiv.org/abs/2405.17927">The Evolution of Multimodal Model Architectures</a> <br/>
  - '<a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a> <br/>'
  - <a href="https://arxiv.org/abs/2201.03545">A ConvNet for the 2020s</a> <br/>
  - <a href="https://arxiv.org/abs/1706.02216">Inductive Representation Learning on Large Graphs</a> <br/>
  - '<a href="https://arxiv.org/abs/1811.01900">Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs</a> <br/>'

- date: 3/11
  title: >
    Week 6 <b>可视化交互技术</b> <a href="lec5 - fusion.pdf">[slides]</a>
  slides:
  topics:
    - Cross-modal interactions <br/>
    - Multimodal fusion
  readings:
    - <a href="https://dl.acm.org/doi/pdf/10.1145/319382.319398">Ten Myths of Multimodal Interaction</a> <br/>
    - <a href="https://www.sciencedirect.com/science/article/pii/S0167865513002584">Multimodal interaction&#58; A review</a> <br/>
    - <a href="https://arxiv.org/abs/2302.12247">Quantifying & Modeling Multimodal Interactions&#58; An Information Decomposition Framework</a> <br/>
    - <a href="https://aclanthology.org/2020.emnlp-main.62/">Does my multimodal model learn cross-modal interactions? It’s harder to tell than you might think!</a> <br/>
